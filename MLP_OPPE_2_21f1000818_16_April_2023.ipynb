{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Badri1903/TATA_PyTraining/blob/master/MLP_OPPE_2_21f1000818_16_April_2023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLP OPPE 2\n",
        "\n",
        "To be filled before the exam starts:\n",
        "\n",
        "**Exam Name**: MLP OPPE 2\n",
        "\n",
        "**Name of the student:** BADRINATH\n",
        "\n",
        "**Roll No. of the student:** 21f1000818\n",
        "\n",
        "**Date:** 16 April 2023\n"
      ],
      "metadata": {
        "id": "XvyHSgS4PgVV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q. 1: Which dataset are you using for this exam?"
      ],
      "metadata": {
        "id": "DkbTpcHnnbCp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "QbDEMsbwy2_H"
      },
      "outputs": [],
      "source": [
        "import numpy as numpy\n",
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv('/content/V1.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q. 2: Break the dataset into features(X) and label (y), where the column satisfaction goes to y and the rest of the columns go to X. How many data points belonging to satisfaction value 1 are there in the dataset ?"
      ],
      "metadata": {
        "id": "Uw1RexjSnhJK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "2FfA0k2KnhJL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77eb5a42-0df1-43bc-c1b0-1d917ec3db94"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    11802\n",
              "1.0     8916\n",
              "Name: satisfaction, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "X = data.drop(['satisfaction'], axis=1)\n",
        "y = data['satisfaction']\n",
        "\n",
        "y.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q. 3: Split the dataset into train and test dataset into the 80:20 ratio while keeping random_state =64. What is the shape of the training label vector(y_train) dataset?\n",
        "\n"
      ],
      "metadata": {
        "id": "koQSKlS2nhsW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "kbGlvaHxnhsX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fde07279-427d-41f0-f655-3763870dab17"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.describe of 12898    0.0\n",
              "19516    1.0\n",
              "1089     0.0\n",
              "12062    0.0\n",
              "18276    0.0\n",
              "        ... \n",
              "7987     1.0\n",
              "9201     0.0\n",
              "16438    0.0\n",
              "3238     1.0\n",
              "6596     0.0\n",
              "Name: satisfaction, Length: 16574, dtype: float64>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=64)\n",
        "y_train.describe"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q. 4: Take LogisticRegression estimator with following parameters for training:\n",
        "\n",
        "> * Use sag as solver\n",
        "> * Set random state to be equal to 64\n",
        "> * Tolerance for stopping criteria to be 1e-3\n",
        "> * Maximum number of iterations taken for the solvers to converge to be\n",
        "100\n",
        "\n",
        "Enter the recall score for the given model using test set(X_test, y_test)"
      ],
      "metadata": {
        "id": "AHyTZdvLnh14"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "J2F4KP8Xnh15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b8bd412-76ac-45b5-8d71-44442acc1f0e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8435599778883361"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "lr = LogisticRegression(solver='sag', tol=1e-3, max_iter=100, random_state=64)\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "y_pred_lr = lr.predict(X_test)\n",
        "\n",
        "lr_score = recall_score(y_test, y_pred_lr)\n",
        "lr_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*(Instruction for Question 5 and 6)*\n",
        "\n",
        "### Instantiate a perceptron classifier with following parameters:-\n",
        "\n",
        ">* Fit the intercept\n",
        ">* Put warm start to be False\n",
        ">* random_state=64\n",
        "\n",
        "### Q. 5: Fit this perceptron model with the training dataset and write the accuracy for the test data."
      ],
      "metadata": {
        "id": "aHvMKZRKnh-N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "rHp9EoVUnh-O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c0efa3d-e625-4f9f-d21c-713a99ea0194"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8424227799227799"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "pr = Perceptron(fit_intercept=True, warm_start=False, random_state=64)\n",
        "pr.fit(X_train, y_train)\n",
        "\n",
        "y_pred_pr = pr.predict(X_test)\n",
        "\n",
        "pr_score = accuracy_score(y_test, y_pred_pr)\n",
        "pr_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q. 6: What is the value of bias (intercept) for the perceptron model you got (upto 1 decimal point) ?\n",
        "\n"
      ],
      "metadata": {
        "id": "wakf2BDAniYB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "MZdT3ZH1niYC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92ab2378-d27a-4a0b-c012-7f080bed2e53"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-10.])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "pr.intercept_"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q. 7: Use SGDClassifier on the training dataset (X_train and y_train) to train the model.\n",
        "\n",
        "Use the following parameters:\n",
        "\n",
        "\n",
        "\n",
        "1.   log_lossis the loss function to be used apply ridge regularization,\n",
        "2.   maximum number of passes over the training data is 10\n",
        "3.   constant learning rate of 0.01,\n",
        "4.   regularization rate value is 0.001,\n",
        "5.   Take random_state=64.\n",
        "6.   Set warm_start as False\n",
        "\n",
        "\n",
        "Note : Please ignore the convergence warning.\n",
        "\n",
        "Using above model, calculate and write the correct value of f1_score for the test set."
      ],
      "metadata": {
        "id": "aU_rpC49nihO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "hyYzgH1unihP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4e61c19-114f-4139-8378-ebef63e6217d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8610721302273364"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "sgdc = SGDClassifier(loss='log_loss', max_iter=10, learning_rate='constant', eta0=0.01, alpha=0.001, random_state=64, warm_start=False)\n",
        "sgdc.fit(X_train, y_train)\n",
        "\n",
        "y_pred_sgdc = sgdc.predict(X_test)\n",
        "\n",
        "sgdc_score = f1_score(y_test, y_pred_sgdc)\n",
        "sgdc_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q. 8: Use Gridsearchcv with KNeighborsClassifier estimator, accuracy as scoring parameter, cv= 5. Consider [1,3,7,11] as K values to be examined.\n",
        "\n",
        "Consider following parameters for KNeighborsClassifier:\n",
        ">* Take metric as 'minkowski',\n",
        ">* Set P value as 2\n",
        "\n",
        "Keep other parameter values as default values.\n",
        "\n",
        "What is the best value of K you obtained using the above instructions?"
      ],
      "metadata": {
        "id": "6G8XIh3Zniox"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "6q6lSNOKniox",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "508c5156-a76f-428f-a3f6-bb0be6b82746"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'n_neighbors': 7}"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "knn = KNeighborsClassifier(metric='minkowski', p=2, )\n",
        "param_grid = {'n_neighbors':[1,3,7,11]}\n",
        "knn_tuned = GridSearchCV(knn, param_grid, scoring='accuracy', cv=5, )\n",
        "knn_tuned.fit(X_train, y_train)\n",
        "knn_tuned.best_params_"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*(Common Instructions for Q9 to Q12)*\n",
        "#### Take DecisionTreeClassifier(random_state = 64) estimator with GridSearchCV. Hyperparameter tuning to be done over the following parameters:\n",
        "\n",
        ">* Criterion as 'entropy' or 'gini'\n",
        ">* Splitter as 'random' or 'best'\n",
        ">* Minimum number of samples per leaf as [2,4,6,8,10]\n",
        ">* Maximum depth as [3,4,5,6]\n",
        ">* Use cross validation = 4\n",
        "\n",
        "Use the best model from above hyper parameter turing process to answer following questions:\n",
        "\n",
        "### Q. 9: Enter the value of the precision on the test set using the best model:\n"
      ],
      "metadata": {
        "id": "Ya6hm0XGniwB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "awg8ffpTniwB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c836895c-fec1-4bf7-debe-1be4fe9a929c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9047619047619048"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import precision_score\n",
        "\n",
        "dtc = DecisionTreeClassifier(random_state=64, )\n",
        "param_grid = {\n",
        "    'criterion' : ['entropy', 'gini'],\n",
        "    'splitter' : ['random', 'best'],\n",
        "    'min_samples_split' : [2,4,6,8,10],\n",
        "    'max_depth' : [3,4,5,6]\n",
        "}\n",
        "dtc_tuned = GridSearchCV(dtc, param_grid, cv=4)\n",
        "dtc_tuned.fit(X_train, y_train)\n",
        "\n",
        "dtc_best = dtc_tuned.best_estimator_\n",
        "y_pred_dtc = dtc_best.predict(X_test)\n",
        "\n",
        "dtc_score = precision_score(y_test, y_pred_dtc)\n",
        "dtc_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q. 10: Enter the value of max_depth of the best estimator you got after training with GridSearchCV."
      ],
      "metadata": {
        "id": "LFc8n8FIni3E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "Bci76g7Qni3F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ff3e574-10e1-4b2f-c566-cfb4cd8a5289"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "dtc_best.max_depth"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q. 11: Enter the value of min_samples_leaf of the best estimator after training with GridSearchCV.\n"
      ],
      "metadata": {
        "id": "x7HT3SDqni9t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "SZVSXKi_ni9u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fd4034a-92a7-49b7-9f8e-2b843b543ffb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "dtc_best.min_samples_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q. 12: What is the number of nodes in the optimal tree?"
      ],
      "metadata": {
        "id": "jRjM0rXdnjFg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "jyO_KmCCnjFh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "986f9a6a-c1e4-4c51-a5ba-510792137a12"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "79"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "dtc_best.tree_.node_count"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q. 13: Take RandomForestClassifier (random state to be 64) with GridSearchCV to tune the number of decision trees with the training set. The number of trees in forest can range from 5 to 10 (both inclusive). Mark the number of decision trees in the best estimator provided by the grid search."
      ],
      "metadata": {
        "id": "DstfuzPRnjOB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "L4CRzjjanjOC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5bb9d38-75a1-4f31-cb2c-461e71209b63"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'n_estimators': 9}"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rfc = RandomForestClassifier(random_state=64)\n",
        "param_grid = {\n",
        "    'n_estimators' : range(5,11)\n",
        "}\n",
        "\n",
        "rfc_tuned = GridSearchCV(rfc, param_grid)\n",
        "rfc_tuned.fit(X_train, y_train)\n",
        "\n",
        "rfc_tuned.best_params_"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*(Common Instructions for Q14,Q15)*\n",
        "### Take an adaboost model with following hyperparameter values and tune it using GridsearchCV.\n",
        ">* Use n_estimators as [10,20,30]\n",
        ">* random_state = 64\n",
        ">* Use learning_rate as [0.5,1,2]\n",
        ">* Take cv value= 5\n",
        "\n",
        "### Q. 14:  Train the 'model' using above instructions and use the best estimator to calculate the total number of misclassified samples for the test data and submit the value."
      ],
      "metadata": {
        "id": "MzU5TSmInjVX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "0PUIl7b1njVX"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "adac = AdaBoostClassifier(random_state=64)\n",
        "param_grid = {\n",
        "    'n_estimators' : [10, 20, 30],\n",
        "    'learning_rate' : [0.5, 1, 2]\n",
        "}\n",
        "\n",
        "adac_tuned = GridSearchCV(adac, param_grid, cv=5)\n",
        "adac_tuned.fit(X_train, y_train)\n",
        "\n",
        "adac_best = adac_tuned.best_estimator_\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "y_pred_adac = adac_best.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred_adac)\n",
        "cm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJVoc0OLvQ69",
        "outputId": "b111bf0c-bd3b-417f-9459-098329d6c636"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2198,  137],\n",
              "       [ 185, 1624]])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q. 15: Mark the value of n_estimators of the best model after training with GridSearchCV."
      ],
      "metadata": {
        "id": "opKcFBPnnjet"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "BtjE6iUgnjet",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a75a9cc-93dc-46ef-f49e-d10e57c8aaaa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "adac_best.n_estimators"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q. 16: Apply GridSearchCV using the support vector machine (SVM) classifier on the training dataset X_train, y_train and calculate the best value of C and kernel from the values below.\n",
        "\n",
        "use below hyperparameter values to tune the mode\n",
        ">* `kernel':['linear', 'rbf'],\n",
        ">* 'C':[1, 10]`)\n",
        "\n",
        "Which of the following options represent the best parameters?"
      ],
      "metadata": {
        "id": "jFNPyqjMnjlp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "wiERjXsqnjlq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d9e56fd-2d3a-436f-eb86-044d06a6c20b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 10, 'kernel': 'rbf'}"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svc = SVC()\n",
        "param_grid = {\n",
        "    'kernel' : ['linear', 'rbf'],\n",
        "    'C' : [1,10]\n",
        "}\n",
        "\n",
        "svc_tuned = GridSearchCV(svc, param_grid)\n",
        "svc_tuned.fit(X_train, y_train)\n",
        "\n",
        "svc_tuned.best_params_"
      ]
    }
  ]
}